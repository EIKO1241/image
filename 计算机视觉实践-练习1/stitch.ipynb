{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import argparse\n",
    "\n",
    "class stitch:\n",
    "    def process(self,paths,mode):\n",
    "        path1,path2=paths\n",
    "        img1=cv2.imread(path1)\n",
    "        img2=cv2.imread(path2)\n",
    "        kp1,feat1=self.get_points(img1)\n",
    "        kp2,feat2=self.get_points(img2)\n",
    "        retval=self.matchs(kp1,kp2,feat1,feat2)\n",
    "        if mode==\"level\":\n",
    "            relt = cv2.warpPerspective(img2, retval, (img1.shape[1] + img2.shape[1], img1.shape[0]))\n",
    "            # 将图片B传入\n",
    "            #relt=relt[0:img1.shape[0], 0:img1.shape[1]]\n",
    "            relt[0:img1.shape[0], 0:img1.shape[1]] = img1\n",
    "            # 计算混合渐变\n",
    "            mask = np.zeros((img1.shape[0], img1.shape[1]), dtype=np.uint8)\n",
    "            mask[:, img1.shape[1]-40:] = 255\n",
    "            relt = cv2.seamlessClone(img1, relt, mask, (img1.shape[1], img1.shape[0]//2), cv2.NORMAL_CLONE)\n",
    "            relt=self.trim_border(relt,mode)\n",
    "        elif mode==\"vertical\":\n",
    "            relt = cv2.warpPerspective(img2, retval, (img1.shape[1], img1.shape[0] + img2.shape[0]))\n",
    "            # 将图片B传入\n",
    "            relt[0:img1.shape[0], 0:img1.shape[1]] = img1\n",
    "            # 计算混合渐变\n",
    "            mask = np.zeros((img1.shape[0], img1.shape[1]), dtype=np.uint8)\n",
    "            mask[img1.shape[0]-40:, :] = 255\n",
    "            relt = cv2.seamlessClone(img1, relt, mask, (img1.shape[1]//2, img1.shape[0]), cv2.MIXED_CLONE)\n",
    "            relt=self.trim_border(relt,mode)\n",
    "        # 返回匹配结果\n",
    "        return relt\n",
    "        pass\n",
    "    \n",
    "    #提取图像的特征点\n",
    "    def get_points(self,img):\n",
    "        # 转换为灰度图\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # 建立SIFT生成器\n",
    "        descriptor = cv2.SIFT_create()\n",
    "        # 检测特征点并计算描述子\n",
    "        kps, features = descriptor.detectAndCompute(gray, None)\n",
    "\n",
    "        kps = np.float32([kp.pt for kp in kps])\n",
    "        return kps, features\n",
    "        pass\n",
    "\n",
    "    #特征点匹配及过滤\n",
    "    def matchs(self,kp1,kp2,feat1,feat2):\n",
    "        # 建立暴力匹配器\n",
    "        matcher=cv2.FlannBasedMatcher()\n",
    "        #matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "        # 使用KNN检测来自AB图的SIFT特征匹配\n",
    "        rawMatches = matcher.knnMatch(feat1, feat2, 2)\n",
    "\n",
    "        # 过滤\n",
    "        matches = []\n",
    "        for m in rawMatches:\n",
    "            if len(m) == 2 and m[0].distance < m[1].distance * 0.75:\n",
    "                matches.append((m[0].trainIdx, m[0].queryIdx))\n",
    "\n",
    "        if len(matches) > 4:\n",
    "            # 获取匹配对的点坐标\n",
    "            ptsA = np.float32([kp1[i] for (_, i) in matches])\n",
    "            ptsB = np.float32([kp2[i] for (i, _) in matches])\n",
    "\n",
    "            # 计算霍夫变换矩阵以及掩码\n",
    "            retval, _ = cv2.findHomography(ptsB, ptsA, cv2.RANSAC, 3.0)\n",
    "            return retval\n",
    "        else:\n",
    "            raise KeyError(\"两张图片不匹配\")\n",
    "        pass\n",
    "\n",
    "    def trim_border(self,image,mode):\n",
    "        # 将彩色图像转换为灰度图像\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        # 查找灰度图像的轮廓\n",
    "        contours,_ = cv2.findContours(gray, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        # 获取最大的轮廓\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "        # 获取凸包\n",
    "        hull = cv2.convexHull(largest_contour)\n",
    "        # 获取凸包的顶点\n",
    "        hull_points = []\n",
    "        for point in hull:\n",
    "            hull_points.append(point[0])\n",
    "        # 计算包围轮廓的最小矩形\n",
    "        bounding_rect = cv2.boundingRect(contours[0])\n",
    "        x, y, w, h = bounding_rect\n",
    "        #获取边角点\n",
    "        rhpoint = None\n",
    "        rbpoint = None\n",
    "        if mode==\"level\":\n",
    "            h = image.shape[0] - 1\n",
    "            for point in hull_points:\n",
    "                if rhpoint is None or (point[1] == 0 and (rhpoint[1] == 0 and point[0] > rhpoint[0])):\n",
    "                    rhpoint = point\n",
    "                if rbpoint is None or (point[1] == h and (rbpoint[1] != h and point[0] > rbpoint[0])):\n",
    "                    rbpoint = point\n",
    "            # 裁剪图像\n",
    "            trimmed_image = image[y:y+h, 0:x+w]\n",
    "            original_points=np.float32([[0,0],rhpoint,rbpoint,[0,h]])\n",
    "            corrected_points=np.float32([[0, 0], [rbpoint[0], 0],rbpoint ,[0,h] ])\n",
    "        else:\n",
    "            w = image.shape[1]-1\n",
    "            for point in hull_points:\n",
    "                if rhpoint is None or (point[0] == 0 and (rhpoint[0] == 0 and point[1] > rhpoint[1])):\n",
    "                    rhpoint = point\n",
    "                if rbpoint is None or (point[0] == w and (rbpoint[0] != w and point[1] > rbpoint[1])):\n",
    "                    rbpoint = point\n",
    "            # 裁剪图像\n",
    "            trimmed_image = image[0:y+h, 0:x+w]\n",
    "            original_points=np.float32([[0,0],[w,0],rbpoint,rhpoint])\n",
    "            corrected_points=np.float32([[0, 0],[w,0],rbpoint,[0,rhpoint[1]]])\n",
    "        \n",
    "\n",
    "        # 计算透视变换矩阵\n",
    "        perspective_matrix = cv2.getPerspectiveTransform(original_points, corrected_points)\n",
    "        # 应用透视变换\n",
    "        corrected_image = cv2.warpPerspective(trimmed_image, perspective_matrix, (trimmed_image.shape[1], trimmed_image.shape[0]))\n",
    "        return corrected_image\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # ap = argparse.ArgumentParser()\n",
    "    # #ap.add_argument(\"--f\", required=False)\n",
    "    # ap.add_argument(\"--left\", required=False,default=r\"image\\example1\\1.jpg\", help=\"path to the first image\")\n",
    "    # ap.add_argument(\"--second\", required=False,default=r\"image\\example1\\2.jpg\", help=\"path to the second image\")\n",
    "    # ap.add_argument(\"--mode\", required=False, default=\"level\", help=\"vertical or level\")\n",
    "    # args = vars(ap.parse_args())\n",
    "\n",
    "    first=r\"image\\example1\\1.jpg\"\n",
    "    second=r\"image\\example1\\2.jpg\"\n",
    "    mode=\"level\"\n",
    "    stitcher=stitch()\n",
    "    result=stitcher.process([first,second],mode)\n",
    "    cv2.imwrite(r'out_put\\output_image.jpg', result)\n",
    "    result=cv2.resize(result,(result.shape[1]//2,result.shape[0]//2))\n",
    "    cv2.imshow(\"Result\",result)\n",
    "    cv2.waitKey(0)\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
